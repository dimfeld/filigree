{% if file_upload %}
//! Object storage functionality for {{model_name}}

use filigree::uploads;
use sqlx::PgConection;

use crate::{
    auth::Authed,
    error::Error,
    server::ServerState
};

/// Apply the storage key template
pub fn generate_object_key(auth: &Authed, id: {{id_type}}, filename: &str) -> String {
    {{file_upload.filename_template_function_body}}
}

pub fn get_storage(state: &ServerState) -> &Storage {
    &state.storage.{{file_upload.bucket}}
}

pub async fn upload_stream<E: Into<Error>>(
    state: &ServerState,
    auth: &Authed,
    tx: &mut PgConnection,
    parent_id: {{belongs_to_field.rust_type}},
    id: Option<{{id_type}}>,
    filename: Option<String>,
    key: Option<String>,
    limit: Option<usize>,
    body: impl Stream<Item=Result<Bytes, E>>
) -> Result<(), Report<Error>> {
    let storage = get_storage(state);

    {% if file_upload.record_size -%}
    let mut file_size = uploads::UploadSize::new(limit);
    {%- endif %}
    {% if file_upload.hash -%}
    let mut hasher = uploads::UploadHasher::<{{file_upload.hash.hasher}}>::new();
    {%- endif %}

    let db_payload = {{struct_base}}UpdatePayload {
        id,
        {{belongs_to_field.name}}: parent_id,
        file_storage_key: Some(file_storage_key),
        file_storage_bucket: "{{file_upload.bucket}}".to_string(),
        {% if file_upload.filename -%}
        file_original_name: filename,
        {%- endif %}
        ..Default::default()
    };

    // Do the upsert first to get the actual ID, since in the single-child case the ID won't change
    // if the object already exists.
    let id = super::queries::upsert_with_parent(
        tx,
        auth.organization_id,
        true,
        parent_id,
        &db_payload
    )
        .await?
        .id;

    let file_storage_key = key.unwrap_or_else(|| generate_object_key(auth, id, filename.as_deref().unwrap_or_default()));

    storage.save_and_inspect_request_body(key, body, |chunk| async {
        {% if file_upload.record_size -%}
        file_size.inspect(chunk).await?;
        {%- endif %}
        {% if file_upload.hash -%}
        hasher.update(chunk).await?;
        {%- endif %}
        Ok::<(), UploadInspectorError>(())
    }).await?;

    {% if file_upload.record_size or file_upload.hash -%}
    // Record the info that we got from the stream itself.
    let recording_payload = {{struct_base}}UpdatePayload {
        id: Some(id),
        {% if file_upload.hash -%}
        file_hash: Some(hasher.finish().as_bytes().to_vec()),
        {%- endif %}
        {% if file_upload.record_size -%}
        file_size: Some(file_size.finish()),
        {%- endif %}
        ..Default::default()
    };

    super::queries::update(&mut *tx, auth, id, recording_payload).await?;
    {%- endif %}

    Ok(())
}

pub async fn upload(
    state: &ServerState,
    authed: &Authed,
    tx: &mut PgConnection,
    parent_id: {{belongs_to_field.rust_type}},
    id: Option<{{id_type}}>,
    filename: Option<String>,
    key: Option<String>,
    limit: Option<usize>,
    body: Bytes
) -> Result<(), Report<Error>> {

    let file_size = body.len();
    if let Some(limit) = limit {
        if file_size > limit {
            return Err(Report::from(UploadInspectorError::FileSizeTooLarge));
        }
    }

    {% if file_upload.hash %}
    let hash = tokio::task::spawn_blocking(|| {
        let mut hasher = uploads::UploadHasher::<{{file_upload.hash.hasher}}>::new();
        hasher.update(&body);
        hasher.finish().as_bytes().to_vec()
    }).await?;
    {% endif %}

    let file_storage_key = key.unwrap_or_else(|| generate_object_key(auth, id, filename.as_deref().unwrap_or_default()));
    let db_payload = {{struct_base}}UpdatePayload {
        id,
        {{belongs_to_field.name}}: parent_id,
        file_storage_key: Some(file_storage_key.clone()),
        file_storage_bucket: "{{file_upload.bucket}}".to_string(),
        {% if file_upload.filename -%}
        file_original_name: filename,
        {%- endif %}
        {% if file_upload.hash -%}
        file_hash: Some(hash),
        {%- endif %}
        {% if file_upload.record_size -%}
        file_size: Some(file_size),
        {%- endif %}
        ..Default::default()
    };

    let id = super::queries::upsert_with_parent(
        tx,
        auth.organization_id,
        true,
        parent_id,
        &db_payload
    )
        .await?
        .id;

    let storage = get_storage(state);
    storage.put(&file_storage_key, body).await?;

    Ok(())
}

/// Delete an object given the storage key
pub async fn delete_by_key(state: &ServerState,  key: &str) -> Result<(), Report<Error>> {
    let storage = get_storage(state);
    storage.delete(key).await?;
    Ok(())
}

pub async fn delete_by_id(
    state: &ServerState,
    auth: &Authed,
    tx: &mut PgConnection,
    id: {{id_type}}
) -> Result<(), Report<Error>> {
    // Look up the object in the database and then delete it

    let storage_key = super::queries::get(
        &mut *tx,
        auth,
        id
    )
        .await?
        .file_storage_key;

    delete_by_key(state, &storage_key).await?;

    super::queries::delete(&mut *tx, auth, id).await?;

    Ok(())
}
{% endif %}
